{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification\n",
    "- Bag of words feature extraction\n",
    "- Training a Naive Bayes classifier\n",
    "- Training a decision tree classifier\n",
    "- Training a maximum entropy classifier\n",
    "- Training scikit-learn classifiers\n",
    "- Measuring precision and recall of a classifier\n",
    "- Calculating high information words\n",
    "- Combining classifiers with voting\n",
    "- Classifying with multiple binary classifiers\n",
    "- Training a classifier with NLTK-Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words feature extraction\n",
    "\n",
    "- The `bag of words` model is the simplest method\n",
    "- It constructs a word presence feature set from all the words of an instance\n",
    "- This method doesn't care about the order of the words\n",
    "- This method doesn't care about how many times a word occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(words):\n",
    "    return dict([(word, True) for word in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to improve the bag of word method? We can...\n",
    "\n",
    "- Construct a set of words that we want to exclude\n",
    " - Filtering stopwords\n",
    "- Including significant bigrams\n",
    " - In addition to single words, it often helps to include significant bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brown': True, 'quick': True, 'fox': True}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def bag_of_words_not_in_set(words, badwords):\n",
    "    return bag_of_words(set(words) - set(badwords))\n",
    "\n",
    "def bag_of_non_stopwords(words, stopfile = 'english'):\n",
    "    badwords = stopwords.words(stopfile)\n",
    "    return bag_of_words_not_in_set(words, badwords)\n",
    "\n",
    "\n",
    "bag_of_non_stopwords(word_tokenize(\"the quick brown fox\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': True,\n",
       " 'quick': True,\n",
       " 'brown': True,\n",
       " 'fox': True,\n",
       " ('brown', 'fox'): True,\n",
       " ('quick', 'brown'): True,\n",
       " ('the', 'quick'): True}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "\n",
    "def bag_of_bigrams_words(words, score_fn = BigramAssocMeasures.chi_sq, n = 200):\n",
    "    bigram_finder = BigramCollocationFinder.from_words(words)\n",
    "    bigrams = bigram_finder.nbest(score_fn, n)\n",
    "    return bag_of_words(words + bigrams)\n",
    "\n",
    "bag_of_bigrams_words(word_tokenize(\"the quick brown fox\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Naive Bayes classifier\n",
    "\n",
    "- Use the `Bayes theorem` to predict the probability that a given feature set belongs to a particular label.\n",
    " - The formula is:  \n",
    "   P(label | features) = P(label) * P(features | label) / P(features)  \n",
    "   > P(label):  \n",
    "       The prior probability of the label occurring, which is the likelihood that a random feature set will have the label.  \n",
    "     P(features | label):  \n",
    "       The prior probability of a given feature set being classified as that label.  \n",
    "     P(features):  \n",
    "       The prior probability of a given feature set occurring.  \n",
    "     P(label | features):  \n",
    "       This tells us the probability that the given features should have that label.\n",
    "- `The split_label_feats should modify.`\n",
    "- During traing, the `NaiveBayesClassifier` class constructs probability distributions for each feature using an `estimator` parameter.  \n",
    " - Default estimator: nltk.probability.ELEProbDist  \n",
    "  - ELE stands for Expected Likelihood Estimate\n",
    "  - The formula for calculating the label probabilities for a given feature is (`c` + 0.5) / (`N` + `B` / 2)  \n",
    "   > `c`: count of times a single feature occurs  \n",
    "     `N`: the total number of feature outcomes observed  \n",
    "     `B`: the number of bins or unique features in the feature set  \n",
    " \n",
    " - Other choices  \n",
    "  - we can use any `estimator` parameter we want, and there are quite a few to choose from.\n",
    "  - The only constraints are that it must inherit from `nltk.probability.ProbDistI` and its constructor must take a `bins` keyword argument.\n",
    "  - For example:\n",
    "   - Using LacplaceProdDist class instead, which uses the formula (`c` + 1) / (`N` + `B`)  \n",
    "   ```\n",
    "   from nltk.probability import LaplaceProbDist  \n",
    "   nb_classifier = NaiveBayesClassifier.train(train_feats, estimator = LaplaceProbDist)  \n",
    "   accuracy(nb_classifier, test_feats)\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def label_feats_from_corpus(corp, feature_detector = bag_of_words):\n",
    "    label_feats = collections.defaultdict(list)\n",
    "    for label in corp.categories():\n",
    "        for fileid in corp.fileids(categories = [label]):\n",
    "            feats = feature_detector(corp.words(fileids = [fileid]))\n",
    "            label_feats[label].append(feats)\n",
    "    return label_feats\n",
    "\n",
    "def split_label_feats(lfeats, split = 0.75):\n",
    "    train_feats = list()\n",
    "    test_feats = list()\n",
    "    for label, feats in lfeats.items():\n",
    "        cutoff = int(len(feats)* split)\n",
    "        train_feats.extend([(feat, label) for feat in feats[:cutoff]])\n",
    "        test_feats.extend([(feat, label) for feat in feats[cutoff:]])\n",
    "    return train_feats, test_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Naive Bayes classifier has labels:  ['neg', 'pos']\n",
      "comment:  the plot was ludicrous\n",
      "predicted category:  neg\n",
      "comment:  kate winslet is accessible\n",
      "predicted category:  pos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.728"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.classify.util import accuracy\n",
    "\n",
    "movie_reviews.categories()\n",
    "lfeats = label_feats_from_corpus(movie_reviews)\n",
    "lfeats.keys()\n",
    "train_feats, test_feats = split_label_feats(lfeats, split = 0.75)\n",
    "nb_classifier = NaiveBayesClassifier.train(train_feats)\n",
    "print('This Naive Bayes classifier has labels: ', nb_classifier.labels())\n",
    "\n",
    "comments = [\"the plot was ludicrous\", \"kate winslet is accessible\"]\n",
    "for comment in comments:\n",
    "    print('comment: ', comment)\n",
    "    print('predicted category: ', nb_classifier.classify(bag_of_words(word_tokenize(comment))))\n",
    "\n",
    "# test the accuracy\n",
    "accuracy(nb_classifier, test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.812"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "sk_classifier = SklearnClassifier(BernoulliNB())\n",
    "sk_classifier.train(train_feats)\n",
    "accuracy(sk_classifier, test_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob[neg] = 0.0000000354\n",
      "prob[pos] = 0.9999999646\n"
     ]
    }
   ],
   "source": [
    "probs = nb_classifier.prob_classify(test_feats[0][0])\n",
    "probs.samples()\n",
    "for key in probs.samples():\n",
    "    print('prob[{}] = {:.10f}'.format(key, probs.prob(key)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most informative features\n",
    "\n",
    "- most_informative_features()\n",
    "- show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             magnificent = True              pos : neg    =     15.0 : 1.0\n",
      "             outstanding = True              pos : neg    =     13.6 : 1.0\n",
      "               insulting = True              neg : pos    =     13.0 : 1.0\n",
      "              vulnerable = True              pos : neg    =     12.3 : 1.0\n",
      "               ludicrous = True              neg : pos    =     11.8 : 1.0\n",
      "             uninvolving = True              neg : pos    =     11.7 : 1.0\n",
      "                  avoids = True              pos : neg    =     11.7 : 1.0\n",
      "              astounding = True              pos : neg    =     10.3 : 1.0\n",
      "             fascination = True              pos : neg    =     10.3 : 1.0\n",
      "                 idiotic = True              neg : pos    =      9.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "nb_classifier.most_informative_features(n = 10)\n",
    "nb_classifier.show_most_informative_features(n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative: Manual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import DictionaryProbDist\n",
    "\n",
    "label_probdist = DictionaryProbDist({'pos': 0.5, 'neg': 0.5})\n",
    "true_probdist = DictionaryProbDist({True: 1})\n",
    "feature_probdist = {('pos', 'yes'): true_probdist, ('neg', 'no'): true_probdist}\n",
    "classifier = NaiveBayesClassifier(label_probdist, feature_probdist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.678"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.classify import DecisionTreeClassifier\n",
    "dt_classifier = DecisionTreeClassifier.train(train_feats,\n",
    "                                             binary = True,\n",
    "                                             entropy_cutoff = 0.8,\n",
    "                                             depth_cutoff = 5,\n",
    "                                             support_cutoff = 30)\n",
    "accuracy(dt_classifier, test_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to use the `DecisionTreeClassifier.train()` class methld?\n",
    "#### Tell the classifier is a binary classifier or not\n",
    "- If the classifier only chooses between two labels, it is a binary classifier\n",
    "- If we have multivalued features, we will want to stick to the default `binary = False`\n",
    "\n",
    "#### Controlling uncertainty with `entropy_cutoff`\n",
    "- Entropy is the uncertainty of the outcome.  \n",
    " - As entropy approaches 1.0, uncertainty increases  \n",
    " - As entropy approaches 0.0, uncertainty decreases\n",
    "\n",
    "- The entropy_cutoff value is used during the tree refinement process  \n",
    "- If the entropy of the probability distribution of label choices in the tree is greater than the entropy_cutoff value, then the tree is refined further by creating more branches.  \n",
    "- If the entropy is lower than the entropy_cutoff value, then tree refinement is halted.  \n",
    "- Entropy is calculated by giving nltk.probability.entropy() a MLEProbDist value created from a FreqDist of label counts.\n",
    "\n",
    "#### Controlling tree depth with `depth_cutoff`\n",
    "- The final decision tree will never be deeper than the deepth_cutoff value  \n",
    " - Default value is 100\n",
    "\n",
    "#### Controlling decisions with `support_cutoff`\n",
    "- The suppor_cutoff values controls how many labeled feature sets are required to refine the tree\n",
    "- Labeled feature sets are eliminated once they no longer provide value to the training process\n",
    "- When the number of labeled feature sets is less than or equal to support_cutoff, refinement stops, at least for that section of the tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a maximum entropy classifier\n",
    "\n",
    "- The MaxentClassifier class is aka conditional exponential classifier or logistic regression classifier.\n",
    "- The maximum entropy classifier converts labeled feature sets to vectors using encoding.\n",
    "- The default algorithm is `iis` (improved iterative scaling)\n",
    " - train_maxent_classifier_with_iis()\n",
    "- A better algorithm is `gis` (general iterative scaling)\n",
    " - train_maxent_classifier_with_gis()\n",
    "- If `megam` is istalled and we specify the `megam` algorithm, then train_maxent_classifier_with_megam() is used\n",
    "- The max_iter variable specifies the maximum number of iterations to go through and update the weights.\n",
    "- The min_lldelta variable specifies the minimum change in the log likelihood required to continue iteratively improving the weights.\n",
    "\n",
    "### Megam algorithm\n",
    "```\n",
    ">>> me_classifier = MaxentClassifier.train(train_feats, algorithm = 'megam', trace = 0, max_iter = 10)\n",
    "[Found megam: ...]\n",
    ">>> accuracy(me_classifier, test_feats)\n",
    "0.8679...\n",
    "```\n",
    "- References:\n",
    " -  https://en.wikipedia.org/wiki/Maximum_entropy_classifier\n",
    " - http://www.umiacs.umd.edu/~hal/megam/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/nltk/classify/maxent.py:1392: RuntimeWarning: overflow encountered in power\n",
      "  exp_nf_delta = 2 ** nf_delta\n",
      "/usr/local/lib/python3.7/site-packages/nltk/classify/maxent.py:1394: RuntimeWarning: invalid value encountered in multiply\n",
      "  sum1 = numpy.sum(exp_nf_delta * A, axis=0)\n",
      "/usr/local/lib/python3.7/site-packages/nltk/classify/maxent.py:1395: RuntimeWarning: invalid value encountered in multiply\n",
      "  sum2 = numpy.sum(nf_exp_nf_delta * A, axis=0)\n",
      "/usr/local/lib/python3.7/site-packages/nltk/classify/maxent.py:1402: RuntimeWarning: invalid value encountered in true_divide\n",
      "  deltas -= (ffreq_empirical - sum1) / -sum2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.classify import MaxentClassifier\n",
    "me_classifier = MaxentClassifier.train(train_feats, trace = 0, max_iter = 1, min_lldelta = 0.5)\n",
    "accuracy(me_classifier, test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.722"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "me_classifier = MaxentClassifier.train(train_feats, algorithm = 'gis',\n",
    "                                       trace = 0, max_iter =  10,\n",
    "                                       min_lldelta = 0.5)\n",
    "accuracy(me_classifier, test_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a scikit-learn classifier\n",
    "\n",
    "### How to train an SklearnClassifier class?\n",
    "- Create training features\n",
    "- Choose and import an sklearn algorithm\n",
    "- Construct an SklearnClassifier class with the chosen algorithm\n",
    "- Train the SklearnClassifier class with our traing features\n",
    "\n",
    "The main difference with NLTK classifiers is that step3 and step4 are usually combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "sk_classifier = SklearnClassifier(MultinomialNB())\n",
    "sk_classifier.train(train_feats)\n",
    "accuracy(sk_classifier, test_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainin with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.892"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "sk_classifier = SklearnClassifier(LogisticRegression())\n",
    "sk_classifier.train(train_feats)\n",
    "accuracy(sk_classifier, test_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with support vector machine\n",
    "- SVC\n",
    "- LinearSVC\n",
    "- NuSVC\n",
    "- Reference\n",
    "http://scikit-learn.org/stable/modules/svm.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.69"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "sk_classifier = SklearnClassifier(SVC())\n",
    "sk_classifier.train(train_feats)\n",
    "accuracy(sk_classifier, test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.864"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "sk_classifier = SklearnClassifier(LinearSVC())\n",
    "sk_classifier.train(train_feats)\n",
    "accuracy(sk_classifier, test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.882"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import NuSVC\n",
    "sk_classifier = SklearnClassifier(NuSVC())\n",
    "sk_classifier.train(train_feats)\n",
    "accuracy(sk_classifier, test_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring precision and recall of a classifier\n",
    "\n",
    "`Precision` and `recall` are two common metrics used to evaluate classifiers.\n",
    "\n",
    "### False positives (Type I error)\n",
    "- Happen when a classifier classifies a feature set with a label it shouldn't have gotten\n",
    "\n",
    "### False negatives (Type II error)\n",
    "- Happen when a classifier doesn't assign a label to a feature that should have it.\n",
    "\n",
    "### Precision\n",
    "- the lack of false positives\n",
    "\n",
    "### Recall\n",
    "- the lack of false negatives\n",
    "\n",
    "### F-measure\n",
    "- Defined as the weighted harmonic mean of precision and recall. If p is the precision, and r is the recall, the formula is: 1/(alpha/p + (1-alpha)/r)  \n",
    " - alpha is a weighing constant that defaults to 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from nltk.metrics.scores import precision\n",
    "from nltk.metrics.scores import recall\n",
    "from nltk.metrics.scores import f_measure\n",
    "\n",
    "def precision_recall(classifier, testfeats):\n",
    "    refsets = collections.defaultdict(set)\n",
    "    testsets = collections.defaultdict(set)\n",
    "    \n",
    "    for i, (feats, label) in enumerate(testfeats):\n",
    "        refsets[label].add(i)\n",
    "        observed = classifier.classify(feats)\n",
    "        testsets[observed].add(i)\n",
    "    \n",
    "    precisions = {}\n",
    "    recalls = {}\n",
    "    \n",
    "    for label in classifier.labels():\n",
    "        precisions[label] = precision(refsets[label], testsets[label])\n",
    "        recalls[label] = recall(refsets[label], testsets[label])\n",
    "    \n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.8988326848249028, recall: 0.924\n",
      "precision: 0.9218106995884774, recall: 0.896\n"
     ]
    }
   ],
   "source": [
    "nb_precisions, nb_recalls = precision_recall(nb_classifier, test_feats)\n",
    "\n",
    "for label in ['pos', 'neg']:\n",
    "    print(\"precision: {}, recall: {}\".format(nb_precisions[label], nb_recalls[label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.8992248062015504, recall: 0.928\n",
      "precision: 0.9256198347107438, recall: 0.896\n"
     ]
    }
   ],
   "source": [
    "me_precisions, me_recalls = precision_recall(me_classifier, test_feats)\n",
    "for label in ['pos', 'neg']:\n",
    "    print(\"precision: {}, recall: {}\".format(me_precisions[label], me_recalls[label]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating high information words\n",
    "\n",
    "A `high information` word is a word that is strongly biased towards a single classification label.\n",
    "- Similar to the `show_most_informative_features()` method on both the NaiveBayesClassifier class and the MaxentClassifier class\n",
    "\n",
    "The `low information` words are words that are common to all labels.\n",
    "- It may be counter-intuitive, but eliminating these words from the training data can actually improve accuracy, recision, and recall\n",
    "\n",
    "### How to get the high_information_words?\n",
    "- The default score function is nltk.metrics.BigramAssocMeasures.chi_sq(), chich calculates the chi-square score for each word using the following parameters:\n",
    " - n_ii: the frequency of the word for the label\n",
    " - n_ix: the total frequency of the word across all labels\n",
    " - n_xi: the total frequency of all words that occurred for the label\n",
    " - n_xx: the total frequency for all words in all labels\n",
    " \n",
    "- Other score functions:\n",
    " - phi_sq() phi-square\n",
    " - pmi() pointwise mutual information\n",
    " - jaccard()\n",
    " - reference: http://www.nltk.org/_modules/nltk/metrics/association.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics import BigramAssocMeasures\n",
    "from nltk.probability import FreqDist, ConditionalFreqDist\n",
    "\n",
    "def high_information_words(labelled_words, score_fn = BigramAssocMeasures.chi_sq, min_score = 5):\n",
    "    word_fd = FreqDist()\n",
    "    label_word_fd = ConditionalFreqDist()\n",
    "    \n",
    "    for label, words in labelled_words:\n",
    "        for word in words:\n",
    "            word_fd[word] += 1\n",
    "            label_word_fd[label][word] += 1\n",
    "    \n",
    "    n_xx = label_word_fd.N()\n",
    "    high_info_words = set()\n",
    "    \n",
    "    for label in label_word_fd.conditions():\n",
    "        n_xi = label_word_fd[label].N()\n",
    "        word_scores = collections.defaultdict(int)\n",
    "    \n",
    "        for word, n_ii in label_word_fd[label].items():\n",
    "            n_ix = word_fd[word]\n",
    "            score = score_fn(n_ii, (n_ix, n_xi), n_xx)\n",
    "            word_scores[word] = score\n",
    "    \n",
    "        bestwords = [word for word, score in word_scores.items() if score >= min_score]\n",
    "        high_info_words |= set(bestwords)\n",
    "\n",
    "    return high_info_words\n",
    "\n",
    "def bag_of_words_in_set(words, goodwords):\n",
    "    return bag_of_words(set(words) & set(goodwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = movie_reviews.categories()\n",
    "labeled_words = [(l, movie_reviews.words(categories=[l])) for l in labels]\n",
    "high_info_words = set(high_information_words(labeled_words))\n",
    "feat_det = lambda words: bag_of_words_in_set(words, high_info_words)\n",
    "lfeats = label_feats_from_corpus(movie_reviews, feature_detector = feat_det)\n",
    "train_feats, test_feats = split_label_feats(lfeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classifier = NaiveBayesClassifier.train(train_feats)\n",
    "accuracy(nb_classifier, test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_precisions, nb_recalls = precision_recall(nb_classifier, test_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining classifiers with voting\n",
    "\n",
    "- One way to improve classification performance is to combine classifiers.\n",
    "- The simplest way to combine multiple classifiers is to use voting, and choose whichever label gets the most votes\n",
    "- It's best to have an odd number of classifiers so that there are no ties\n",
    "- The individual classifiers should also use different algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from nltk.classify import ClassifierI\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "class MaxVoteClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "        self._labels = sorted(set(itertools.chain(*[c.labels() for c in classifiers])))\n",
    "\n",
    "    def labels(self):\n",
    "        return self._labels\n",
    "    \n",
    "    def classify(self, feats):\n",
    "        counts = FreqDist()\n",
    "        \n",
    "        for classifier in self._classifiers:\n",
    "            counts[classifier.classify(feats)] += 1\n",
    "        \n",
    "        return counts.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_classifier = MaxVoteClassifier(nb_classifier, dt_classifier, me_classifier, sk_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mv_classifier.labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.908"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(mv_classifier, test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg: precision - 0.9146341463414634, recall - 0.9\n",
      "pos: precision - 0.9015748031496063, recall - 0.916\n"
     ]
    }
   ],
   "source": [
    "mv_precisions, mv_recalls = precision_recall(mv_classifier, test_feats)\n",
    "for label in mv_classifier.labels():\n",
    "    print('{}: precision - {}, recall - {}'.format(label, mv_precisions[label], mv_recalls[label]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying with multiple binary classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import reuters\n",
    "len(reuters.categories())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reuters_high_info_words(score_fn = BigramAssocMeasures.chi_sq):\n",
    "    labeled_words = []\n",
    "    \n",
    "    for label in reuters.categories():\n",
    "        labeled_words.append((label, reuters.words(categories=[label])))\n",
    "    \n",
    "    return high_information_words(labeled_words, score_fn = score_fn)\n",
    "\n",
    "def reuters_train_test_feats(feature_detector = bag_of_words):\n",
    "    train_feats = []\n",
    "    test_feats = []\n",
    "    for fileid in reuters.fileids():\n",
    "        if fileid.startswith('training'):\n",
    "            featlist = train_feats\n",
    "        else:\n",
    "            featlist = test_feats\n",
    "        feats = feature_detector(reuters.words(fileid))\n",
    "        labels = reuters.categories(fileid)\n",
    "        featlist.append((feats, labels))\n",
    "    return train_feats, test_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "rwords = reuters_high_info_words()\n",
    "featdet = lambda words: bag_of_words_in_set(words, rwords)\n",
    "multi_train_feats, multi_test_feats = reuters_train_test_feats(featdet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a classifier with NLTK-Trainer\n",
    "\n",
    "- https://github.com/japerk/nltk-trainer\n",
    "- http://nltk-trainer.readthedocs.org/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
